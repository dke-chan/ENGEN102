---
title: "Inference for a Difference in Means"
author: "ENGEN102-23G (HAM) - Engineering Maths and Modelling 1B"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    auto-stretch: false
    height: 1080
    width: 1920
    theme: reveal-extra/quartz.scss
    template-partials:
      - reveal-extra/title-block.html
    highlight-style: breeze
    code-line-numbers: false
    embed-resources: true
editor: source
---
  
```{r setup}
#| include: false
library(knitr)
library(ggplot2)
```

## Motivation

::: {style="margin-bottom: 50px;"}
The kind of data we typically analyse when we measure one numeric variable and one categorical variable on each observation. Often, we collect this data to *detect a difference* between two groups.
:::

. . .

> Do women who smoke during pregnancy have babies with lower average birth weight than women who don't smoke during pregnancy? If so, what is the difference?

::: {style="font-size: 0.9em; text-align: right; margin-top: -0.5em;"}
 --- Utts and Heckard (2015)
:::

::: {.aside}
Utts, J. M. & Heckard, R. F. (2015). *Mind on Statistics* (5th ed.). Cengage.
:::

## Sampling Distribution of the Difference in Sample Means

Another outcome of the *Central Limit Theorem* is the **sampling distribution of the difference in sample means**.

. . .

::: {.definition style="margin-top: 50px; width: 90%;"}
Let $X_1, X_2, \cdots, X_n$ be $n$ independent and identically distributed **random variables** with *finite* mean, [$\mu_X$]{.blue}, and standard deviation, [$\sigma_X$]{.blue}.

Furthermore, let $Y_1, Y_2, \cdots, Y_n$ be $n$ independent and identically distributed **random variables** with *finite* mean, [$\mu_Y$]{.blue}, and standard deviation, [$\sigma_Y$]{.blue}.

If we let $\bar{X} = \frac{\sum^n_{i=1} X_i}{n_X}$ and $\bar{Y} = \frac{\sum^n_{i=1} Y_i}{n_Y}$, then

$$
\bar{X} - \bar{Y} \rightarrow_D \text{Normal} \! \left(\mu = \mu_X - \mu_Y, \sigma = \sqrt{\frac{(\sigma_X)^2}{n_X} + \frac{(\sigma_Y)^2}{n_Y}}\right)
$$
:::

. . .

::: {style="margin-top: 50px;"}
Like the *sampling distribution of the sample mean*, $n_1 + n_2 \geq 30$ is "good enough" to use a Normally distributed **random variable** to model $\bar{X} - \bar{Y}$.
:::

## Standard Error of *x&#772;*~1~ &minus; *x&#772;*~2~

The *estimate* of the sampling distribution's *spread* given the **observed data**.

. . .

::: {.definition style="margin-top: 50px; width: 90%;"}
Let:

- $\bar{x}_1$ and $\bar{x}_2$ be the *sample means* of each group,
- $s_1$ and $s_2$ be the *sample standard deviations* of each group,
- and $n_1$ and $n_2$ be the *sample sizes* of each group.

Hence, the standard error of $\bar{x}_1 - \bar{x}_2$ is defined as

$$
\text{se}(\bar{x}_1 - \bar{x}_2) = \sqrt{\frac{(s_1)^2}{n_1} + \frac{(s_2)^2}{n_2}}
$$
:::

. . .

::: {.dummy style="margin-top: 50px;"}
This definition of $\text{se}(\bar{x}_1 - \bar{x}_2)$ *does not* assume that the underlying standard deviations of each group are the same.
:::

::: {.aside}
**Note:** $\bar{x}_1 - \bar{x}_2$ is the *estimate* of the sampling distribution's *centre* given the **observed data**.
:::


## [Ex 6:]{.red} Handedness and Earnings

<blockquote style="border-left: 0.25em solid #685f5f;">
Could handedness be a factor that explains differences in the average hourly earnings? Ruebeck et al. (2007) randomly sampled 2295 American men and numerically summarised the recorded hourly earnings (measured in USD) by handedness below.
</blockquote>

$$
\bar{x}_\text{Left} = \$13.40, \quad s_\text{Left} = \$7.9, \quad n_\text{Left} = 268 \\
\bar{x}_\text{Right} = \$13.10, \quad s_\text{Right} = \$7.9, \quad n_\text{Right} = 2027
$$

::: {.aside}
Ruebeck, C. S., Harrington Jr, J. E., & Moffitt, R. (2007). Handedness and earnings. *Laterality*, **12**(2), 101--120.
:::

## Estimation of the Difference in Means

:::::: {.columns}
::::: {.column}
**Point Estimate**

::: {.definition style="width: 15%; margin-left: 0;"}
$\bar{x}_1 - \bar{x}_2$
:::

:::: {.fragment}
::: {style="margin-top: 50px;"}
**Interval Estimate^[By constructing a *[confidence interval]{.tomato}* for the difference in the "true" means.]**
:::

::: {.definition-orchid style="width: 58%; margin-left: 0;"}
 $\bar{x}_1 - \bar{x}_2 \pm t^*_p(\nu) \times \text{se}(\bar{x}_1 - \bar{x}_2)$
:::
::::

:::: {.fragment .incremental}
where $t^*_p(\nu)$ is the *t*-multiplier such that:

::: {style="margin-top: -15px;"}
- $p = 1 - \text{Conf. Level}/2$ 
- $\nu = \text{min}(n_1 - 1, n_2 - 1)$ [*by hand*]{.fragment .highlight-blue}^[Statistically inclined software like [Python]{.cornflowerblue} use Satterthwaite's approximation to determine $\nu$.]
:::
::::
:::::
::::: {.fragment .column}
Recall for [**Ex 6:**]{.red}
<blockquote style="border-left: 0.25em solid #685f5f; margin-bottom: 50px;">
$$
\bar{x}_\text{Left} = \$13.40, \quad s_\text{Left} = \$7.9, \quad n_\text{Left} = 268 \\
\bar{x}_\text{Right} = \$13.10, \quad s_\text{Right} = \$7.9, \quad n_\text{Right} = 2027
$$
</blockquote>

```{python noise-multiplier}
#| echo: true
#| classes: fragment

# Load in the stats submodule from the scipy package
from scipy import stats

# Determine the t-multiplier for a 95% C.I.
stats.t.ppf(0.975, 267)
```
:::::
::::::

## Interpretation of the Confidence Interval

[**Ex 6:**]{.red} The 95% C.I. for $\mu_\text{Left} - \mu_\text{Right}$ is $(-0.7711021 , 1.3711021)$

. . .

<ul style="margin-top: 25px;">
  <li style="line-height: 1.1;">A [positive]{.tomato} number means that the true mean of the *first* group was estimated to be **greater than** that of the *second* group.</li>
  <li class="fragment" style="line-height: 1.1;">A [negative]{.steelblue} number means that the true mean of the *first* group was estimated to be **lower than** that of the *second* group.</li>
  <li class="fragment" style="line-height: 1.1;">You can "invert" the signs of the C.I. to interpret it the other way around. Hence, the 95% C.I. for $\mu_\text{Right} - \mu_\text{Left}$ is? [$(-1.3711021, 0.7711021)$]{.printOnly}</li>
</ul>

::: {.printOnly style="margin-top: 50px;"}
With 95% confidence, we estimate that the true mean hourly earnings of left-handed American men were somewhere between \$0.77 per hour lower and \$1.37 per hour higher than that of right-handed American men.
:::

## Test for the Difference in Means<small>1</small>

:::::: {.columns}
::::: {.column}
**Hypothesis Statements^2^**

::: {.definition style="width: 35%; margin-left: 0;"}
$H_0\!: \mu_1 - \mu_2 = h_d$  
$H_1\!: \mu_1 - \mu_2 \neq h_d$
:::

::: {.fragment}
where $h_d$ is the hypothesised difference in <br> the "true" means.
:::

:::: {.fragment}
::: {style="margin-top: 50px;"}
**Test Statistic**
:::

::: {.definition-orchid style="width: 40%; margin-left: 0;"}
$t_0 = \displaystyle \frac{(\bar{x}_1 - \bar{x}_2) - h_d}{ \text{se}(\bar{x}_1 - \bar{x}_2)}$
:::
::::
:::::
::::: {.fragment .column}
Recall for [**Ex 6:**]{.red}
<blockquote style="border-left: 0.25em solid #685f5f; margin-bottom: 50px;">
$$
\bar{x}_\text{Left} = \$13.40, \quad s_\text{Left} = \$7.9, \quad n_\text{Left} = 268 \\
\bar{x}_\text{Right} = \$13.10, \quad s_\text{Right} = \$7.9, \quad n_\text{Right} = 2027
$$
</blockquote>
:::::
::::::

::: {.aside}
1. By conducting a two sample *t*-test, that is, a [*hypothesis test*]{.steelblue} for the difference in the "true" means.
2. By default, we conduct two-sided hypothesis tests ($\neq$). A one-sided test can be conducted instead by changing the sign of the *alternative* hypothesis to $<$ or $>$.
:::

## Using Student's *t*-distribution to Calculate the *p*-value

[**Ex 6:**]{.red} $t_0 = 0.584$ for $H_0\!: \mu_\text{Left} - \mu_\text{Right} = 0$ versus $H_1\!: \mu_\text{Left} - \mu_\text{Right} \neq 0$.

. . .

::: {style="margin-bottom: 50px;"}
Under the *null*, $T \rightarrow_D \text{Student}(\nu)$, where $\nu = \text{min}(n_1 - 1, n_2 - 1)$ [*by hand*]{.highlight-blue-revealjs}^[Statistically inclined software like [Python]{.cornflowerblue} use Satterthwaite's approximation to determine $\nu$.].
:::

::::: {.columns style="font-size: 0.9em;"}
:::: {.column .fragment}
::: {.definition style="width: 85%; margin-left: 0;"}
If it is a two-sided test, e.g. $H_1 \! : \mu_1 - \mu_2 \neq h_d$

$\quad p\text{-value} = 2 \times \mathbb{P}(T > |t_0|)$

$\quad \text{Critical value, } t, ~ \text{fulfills:} ~ \mathbb{P}(T > |t|) = \alpha/2$
:::

::: {.definition-orchid .fragment style="margin-top: 25px; width: 85%; margin-left: 0;"}
If it is a one-sided test and $H_1 \! : \mu_1 - \mu_2 > h_d$

$\quad p\text{-value} = \mathbb{P}(T > t_0)$

$\quad \text{Critical value, } t, ~ \text{fulfills:} ~ \mathbb{P}(T > t) = \alpha$
:::

::: {.definition-teal .fragment style="margin-top: 25px; width: 85%; margin-left: 0;"}
If it is a one-sided test and $H_1 \! : \mu_1 - \mu_2 < h_d$

$\quad p\text{-value} = \mathbb{P}(T < t_0)$

$\quad \text{Critical value, } t, ~ \text{fulfills:} ~ \mathbb{P}(T < t) = \alpha$
:::
::::
:::: {.column}
```{python noise-pvalue}
#| echo: true
#| classes: fragment

# Load in the stats submodule from the scipy package
from scipy import stats

# Calculate the p-value using the CDF
2 * (1 - stats.t.cdf(abs(0.584), 274))

# Determine the critical value at the 5% level
stats.t.ppf(0.975, 274)
```
::::
:::::

## Explanation of the Outcome of the Hypothesis Test

[**Ex 6:**]{.red} $t_0 = 0.584$ for $H_0\!: \mu_\text{Left} - \mu_\text{Right} = 0$ versus $H_1\!: \mu_\text{Left} - \mu_\text{Right} \neq 0$.

The *p*-value was 0.5597 and the critical value was 1.969.

::: {.printOnly style="margin-top: 50px;"}
We do not reject the null that the true average hourly earnings of left-handed American men were the same as that of right-handed American men in favour of the alternative that they are not at the 5% level (p-value = 0.5597). 
:::


## [Ex 7:]{.red} Jet Noise

::::: {.columns}
:::: {.column width="70%"}
<blockquote style="border-left: 0.25em solid #685f5f;">
The `jet-noise.csv` file describes a study investigated the noise levels of a random sample of wide-bodied jets, and narrow-bodied jets were measured immediately after their wheels left the ground at an international airport. Why noise levels? The researchers thought it may influence the frequency of birds being hit by aircraft (as it is regarded as a safety hazard).
</blockquote>

::: {.fragment fragment-index=1 .orchid-table style="font-size: 0.9em; margin-top: 50px; width: 90%;"}
+:----------+:----------------------------------------------------------------------------------------------------------------------------+
| **noise** | A number that denotes the noise level after the jet takes off, measured in decibels (dB). 
+-----------+-----------------------------------------------------------------------------------------------------------------------------+
| **body**  | A string that denotes the body type of the jet, either `wide` (for wide-bodied) or `narrow` (for narrow-bodied). 
+-----------+-----------------------------------------------------------------------------------------------------------------------------+
:::
::::
:::: {.column width="30%" .fragment fragment-index=0}
```{r noise} 
#| results: asis
#| classes: excel

noise.df <- read.csv("datasets/jet-noise.csv")
 
rbind(colnames(noise.df), head(noise.df, n = 14), rep("...", ncol(noise.df))) |>
  kable(format = "html", row.names = TRUE, col.names = LETTERS[1:ncol(noise.df)])
```
::::
:::::

::: {.aside}
Data from Wild, C. J., & Seber, G. A. F. (2000). *Chance Encounters: A First Course in Data Analysis and Inference*. Wiley.
:::

## Assumptions for Inference on the Difference in Means

::::: {.columns}
:::: {.column width="45%"}
```{r noise-dotplot}
#| fig-dpi: 300
#| fig-height: 4.5
#| fig-width: 7
#| out-width: 90%
#| fig-align: center
#| fig-cap: "**Figure:** Distribution of 35 jet noise levels after takeoff."

ggplot(noise.df, aes(x = noise)) +
  geom_dotplot(fill = NA, stroke = 3, colour = "black", binwidth = (max(noise.df$noise) - min(noise.df$noise)) / 25, dotsize = 0.7) + 
  facet_wrap(~ body, nrow = 2, labeller = as_labeller(c(`narrow` = "Narrow-bodied Jets", `wide` = "Wide-bodied Jets"))) +
  scale_y_continuous(breaks = NULL) +
  labs(y = NULL, x = "Noise Level After Takeoff (dB)", title = "Distribution of Noise Levels After Takeoff by Body Type") +
  theme_bw()
```
::::
:::: {.column width="55%"}
<ol>
  <li class="fragment" data-fragment-index=0> The two groups are independent.</li>
  <li class="fragment" data-fragment-index=1> *Within* group: <ol style="list-style-type: lower-alpha; ">
    <li class="fragment" data-fragment-index=1 style="line-height: 1.1;"> Observations are independent.</li>
    <li class="fragment" data-fragment-index=2 style="line-height: 1.1;"> One measure of centre is an appropriate summary of the data.</li>
    <li class="fragment" data-fragment-index=3 style="line-height: 1.1;"> The data is approximately symmetrical about its sample mean.</li>
    <li class="fragment" data-fragment-index=4 style="line-height: 1.1;"> No outliers.</li>
  </ol></li>
</ol>

::: {.fragment fragment-index=5 style="margin-top: 50px;"}
Like _**Inference on the Mean**_, we are more lenient with the final two *within* group assumptions for *large* sample sizes.
:::
::::
:::::

## [Ex 7]{.red} Inferential Statistics in [Python]{.cornflowerblue}

::: {style="width: 85%;"}
```{python Ex-7}
#| echo: true

# Load in one submodule from the scipy package and the pandas package
from scipy import stats
import pandas

# Read in the jet-noise.csv file
noise_df = pandas.read_csv("datasets/jet-noise.csv")

# Group the data by body
noise_grouped = noise_df.groupby(["body"])

# Calculate the inferential statistics
noise_ttest = stats.ttest_ind(
  a = noise_grouped.get_group("wide")["noise"], 
  b = noise_grouped.get_group("narrow")["noise"], 
  equal_var = False, alternative = "two-sided"
)

# Print the constructed 95% confidence interval
noise_ttest.confidence_interval(confidence_level = 0.95)

# Print the result of the hypothesis test, whose alternative hypothesis was specified above
noise_ttest
```
:::

::: {.aside}
**Documentation**: [docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind)
:::

## Practice Exercises {visibility="uncounted"}

<ol style="line-height: 1.1; font-size: 0.8em;">
  <li style="margin-bottom: 50pt;">
    <ol>
      <li style="list-style-type: lower-alpha; line-height: 1.1; font-size: 1em;">
      Interpret the 95% confidence interval constructed for [**Ex 7**]{.red}.
      </li>
      <li style="list-style-type: lower-alpha; line-height: 1.1; font-size: 1em;">
      Explain the outcome of the hypothesis test conducted for [**Ex 7**]{.red} at the 5% level.
      </li>
    </ol>
  </li>
  
  <li style="margin-bottom: 50pt;">
  Suppose we plotted data typically analysed when conducting inference for a difference in means. Which assumptions for inference can be checked with the plot?
  </li>
  
  <li>
  A company producing batteries wishes to see if there is any difference between the lifetime of two recently developed battery prototypes, battery A and battery B. Quality assurance tested a random sample of 15 battery As, and 12 battery Bs, and the results of the test are numerically summarised below.
$$
\bar{x}_\text{A} = 145 ~ \text{days}, \quad s_\text{A} = 18 ~ \text{days}, \quad n_\text{A} = 15 \\
\bar{x}_\text{B} = 162 ~ \text{days}, \quad s_\text{B} = 12 ~ \text{days}, \quad n_\text{B} = 12
$$
  You can answer the following questions as if the assumptions for inference have been met.
    <ol>
      <li style="list-style-type: lower-alpha; line-height: 1.1;">
      Construct a 95% confidence interval for the difference in mean lifetimes.
      </li>
      <li style="list-style-type: lower-alpha; line-height: 1.1;">
      Interpret the 95% confidence interval.
      </li>
      <li style="list-style-type: lower-alpha; line-height: 1.1;">
      State the null *and* alternative hypothesis statements that can be used to answer the company's question.
      </li>
      <li style="list-style-type: lower-alpha; line-height: 1.1;">
      Based on your hypotheses, calculate the test statistic *and* determine the critical value.
      </li>
      <li style="list-style-type: lower-alpha; line-height: 1.1;">
      Explain the outcome of the hypothesis test conducted at the 5% level.
      </li>
      <li style="list-style-type: lower-alpha; line-height: 1.1;">
      Based on your answers above, make a conclusion on whether there is a difference between the lifetime of the two battery prototypes.
      </li>
    </ol>

  </li>
</ol>
