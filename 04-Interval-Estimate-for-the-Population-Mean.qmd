---
title: "An Interval Estimate for the Underlying Mean"
author: "ENGEN102-23B (HAM) & (SEC) - Engineering Maths and Modelling 1B"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    auto-stretch: false
    height: 1080
    width: 1920
    theme: reveal-extra/quartz.scss
    template-partials:
      - reveal-extra/title-block.html
    highlight-style: ayu
    code-line-numbers: false
    embed-resources: true
editor: source
---

## [Introduction to Statistical Inference]{.fragment} {.margin-bottom}

So far we have covered the following:

where $t^*_p(\nu)$ is the *t*-multiplier for the $p$th percentile of a Student's *t*-distribution with $\nu$ degrees of freedom

::: {.tightList style="margin-left: 1em;"}
1. Summarise and describe data
2. The concept of modelling outcomes of a random process, with a focus on the Normal distribution
3. A convenient way to model the potential sample mean from $n$ realisations of a random process^[Under some assumptions]
:::

. . .

Points 2. and 3. allow us to develop methods to infer parameters, such as a **random variable's** underlying mean, with *only* one sample

## Confidence intervals

:::: {style="width: 90%; display: block; margin: auto;"}
> A **confidence interval** for a parameter is an interval computed from sample data by a method that will capture the parameter for a specified proportion of all samples.
> 
> The success rate (proportion of all samples whose intervals contain the parameter) is known as the **confidence level**.

::: {style="font-size: 0.8em; text-align: right; margin-top: -1em;"}
 --- Lock et al. (2021)
:::

::::

::: {.aside}
Lock, R. H., Lock P. F., Morgan, K. L., Lock, E. F., & Lock, D. F. (2021). *Statistics: Unlocking the power of data* (3rd ed.). Wiley.
:::

## [Definition:]{style="color: darkorange;"} (1 - *&alpha;*)% confidence interval for *&mu;*

::: {.definition style="width: 40%;"}
$$
\bar{x}  \pm  t^*_{1-\alpha/2}(\nu) \times \text{se}(\bar{x})
$$
:::

. . .

where:

::: {.incremental style="font-size: 0.9em; margin-top: -0.25em;"}
- $\bar{x}$ is the **sample** mean
- $n$ is the number of observations
- The confidence level is $(1 - \alpha)$, where $\alpha$ is a **proportion**
- The degrees of freedom, $\nu$
  - For a $(1 - \alpha)$ C.I. for $\mu$, we set this to $\nu = n - 1$
- $t^*_{1-\alpha/2}(\nu)$ is the *t*-multiplier for the prescribed confidence level of $(1 - \alpha)$
  - For example, a confidence level of 95% results in $t^*_{0.975}(\nu)$
- $\text{se}(\bar{x})$ is the **standard error** of $\bar{x}$
:::

## *t*-multipliers[...?]{.fragment} {.margin-bottom}

They are derived from the Student's *t*-distribution, which has one parameter $\nu$ and this parameter is often coined as the *degrees of freedom*

. . .

A *t*-multiplier, $t^*_{1-\alpha/2}(\nu)$, is a *cumulative function* takes a percentile^[That is, a percentage] and $\nu$

. . .

It calculates the precise value where the area under the curve is equal to the percentile for a given value of $\nu$

. . .

**A fact we will not prove:** It turns out that the *t*-multiplier is the critical scaling factor of $\text{se}(\bar{x})$ to ensure that our interval method "works" for $(1 - \alpha)\%$ of all potential random samples

## [Ex 5:]{style='color: tomato;'} Student Textbook Spending

> A randomly selected sample of 16 students at a university was asked: "How much did you spend on textbooks this semester?" The amount spent by each sampled student has been numerically summarised below
$$\bar{x} = 284.92, \quad\quad s = 96.06, \quad\quad n = 16$$
Construct a 95% confidence interval for the underlying mean amount all students spend on textbooks. Then interpret the constructed confidence interval

. . .

::: {style="width: 55%; margin-top: 25px;"}
```{python}
#| echo: true
# A Python script to print the exact value of the t-multiplier
from scipy.stats import t
t.ppf(0.975, df=15)
```
:::


[233.7681 336.0720]{style="color: ghostwhite;"}

## [Ex 1]{style='color: tomato;'} in [iNZight]{.R}

:::::: {.columns}
::::: {.column style="width: 50%;"}
```{r}
#| echo: false
#| classes: output-small-80
library(iNZightPlots)
davidsSample.df <- read.csv("datasets/davids-sample.csv")
inzsummary(~ Weight, data = davidsSample.df, width = 83, summary.type = "inference", inference.type = "conf", hypothesis = NULL)
```
:::::

::::: {.column .margin-bottom .fragment style="width: 50%;"}
**Assumptions**  
[One measure of centre is appropriate for David's sample, and the values are approximately symmetrical about the sample mean. However, David may not have randomly selected the blocks... So the independence assumption might not be met.]{style="font-size: 0.9em;"}

:::: {.fragment}
**Interpretation**  
[With 95% confidence, we estimate that the mean block weight is somewhere between 22.35 and 37.79 grams.]{style="font-size: 0.9em;"}
::::
:::::
::::::

## What a confidence interval is *not*

Suppose the confidence level is 95%. The following interpretations of a 95% confidence interval are [wrong]{style="color: red;"}:

::: {.incremental style="margin-left: 1em;"}
1. A 95% confidence interval contains 95% of the data in the population
2. I am 95% sure that the mean of a sample will fall within a 95% confidence interval for the mean
3. The probability (chance) that the population parameter is in this particular 95% confidence interval is 0.95
:::

::: {.aside}
Lock, R. H., Lock P. F., Morgan, K. L., Lock, E. F., & Lock, D. F. (2021). *Statistics: Unlocking the power of data* (3rd ed.). Wiley.
:::
